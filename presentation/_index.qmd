---
title: |
    ![](media/banner.png){width=65%}<br />
    **TRUE TEAMWORK**<br />
subtitle: |
    Building Human-AI Partnerships<br />
    for Tomorrow's Cyber Challenges<br /><br />

title-meta: 'Straight, Honomichl, & Wagner - "True Teamwork" - NICE K12 2025'

title-slide-attributes:
  data-notes: |
      Thank you for joining us for "True Teamwork!"

      Today we're going to show you practical activities for teaching students to work WITH AI as teammates in cybersecurity. Not competing with it, not just using it as a tool, but genuinely collaborating.
      
      [Introductions]

      We have **45 minutes together**. Quick context, then we dive into **three activities** you can try right here, right now. Let's go!

author:
  - name: Ryan Straight
    orcid: 0000-0002-6251-5662
    email: ryanstraight@arizona.edu
  - name: Rob Honomichl
    orcid: 0009-0001-0968-2277
    email: rjhonomichl@arizona.edu
  - name: Paul Wagner
    orcid: 0000-0001-5914-0479
    email: paulewagner@arizona.edu

countdown:
  color_running_background: "#0C234B"
  color_running_text: "#FFFFFF"
  color_warning_background: "#AB0520"
  color_warning_text: "#FFFFFF"
  color_finished_background: "#AB0520"
  color_finished_text: "#FFFFFF"
  font_size: "3rem"

format:
  revealjs:
    theme: simple
    css: ../assets/nice-k12-style.css
    controls: true
    controls-tutorial: true
    logo: "media/banner.png"
    footer: 'Straight, Honomichl, & Wagner - "True Teamwork" - NICE K12 2025'
    slide-number: true
    show-slide-number: all
    transition: slide
    background-transition: fade
    embed-resources: false
    output-file: "index"
---

# {#follow-along data-menu-title="Get Your Materials NOW" background-image="media/banner.png" background-size="30%" background-position="right 5% top 5%"}

<br /><br />

[GET YOUR STUFF NOW!]{.r-fit-text}

::: {.all="revert"}
![](media/icon-rocket.apng){fig-align="center" width=150}
:::

## {#material-links data-menu-title="Materials"}

:::: {.columns}

::: {.column width="35%"}
![](media/qr-nicek12.png)

![](media/arrow.apng){width=80} also there!
:::

::: {.column width="65%"}
<br />

#### Download&nbsp;Materials&nbsp;Right&nbsp;Now!

[ryanstraight.github.io/nicek12&#x2011;2025&#x2011;materials](https://ryanstraight.github.io/nicek12-2025-materials/)

**You get:**

- **Quick Start guide** (try it Monday!)
- Low-resource options  
(no 1:1 devices? no problem)
- 12 lesson plans  
(3 activities √ó 4 grade bands)
- Ready-to-print *everything*
:::

::::

::: {.notes}
FIRST THING: Scan this QR code. Download the materials while we talk, everything we cover today is in there, plus more.

Honest note: First time through? Budget 2 hours prep. After that, 30-45 minutes. The Quick Start guide walks you through exactly what to do first.

You're about to experience THREE activities‚Äîcompressed versions of what your students will do. Pay attention to what YOU notice. Ready? Let's go!
:::

## The Shift We're Preparing Students For

:::: {.columns}
::: {.column width="50%"}
**How we often teach AI:**

- AI as a tool to use
- AI as a threat to guard against
- AI as something to regulate
:::

::: {.column width="50%"}
::: {.fragment}
**What the workforce actually needs:**

- AI as a **partner** with different strengths
- Humans who know when to trust‚Äîand verify
- Teams that leverage both
:::
:::
::::

::: {.notes}
60 seconds of context before we dive in.

Here's the shift: We often teach AI as a tool: something students USE. Or as a threat: something to guard against. Or as a policy problem‚Äîsomething to regulate.

But in actuality, we're seeing AI as a partner. Security Operations Centers are drowning in alerts; thousands per day. AI triages them, prioritizes them, spots patterns. But humans decide what's real, what to escalate, what to do. That's not future-state. That's TODAY.

The professionals of the future who will thrive are the ones who know how to work WITH AI: when to trust it, when to verify it, when to override it.

That's what these activities teach. Not AI literacy. Not AI ethics in the abstract. Partnership skills.

Let's experience it.
:::

# {#theoretical-grounding data-menu-title="The Research Foundation" background-color="#0C234B" background-image="media/banner_reverse.png" background-size="30%" background-position="right 5% top 5%"}

<br /><br />

[WHY THIS WORKS]{.r-fit-text}

::: {.all="revert"}
![](media/icon-brain.apng){fig-align="center" width=150}
:::

::: {.notes}
Before we jump into the activities, I want to share the 60-second version of WHY we designed them this way.

This isn't just "let's use AI in class." There's research behind how we structured these experiences.

If you're academically inclined, the full annotated bibliography is in your download. For now‚Äîthe practical version.
:::

## The Partnership Framework {.smaller}

:::: {.columns}
::: {.column width="55%"}
::: {.glass-card}
**Three ideas shaped these activities:**

1. **Distributed agency** ‚Äî Expertise is shared between humans and AI (this is how SOCs actually work)

2. **Complementary strengths** ‚Äî AI sees patterns; humans see context and meaning

3. **Mutual shaping** ‚Äî We change AI through how we query it; AI changes us through what it surfaces
:::
:::

::: {.column width="45%"}
::: {.fragment}
**In practice:**

A SOC analyst doesn't "use" a SIEM‚Äîthey *work with* it.

The SIEM decides what's worth flagging.

The analyst decides what it means.

**Together:** threat detection.

**Apart:** blind spots.
:::
:::
::::

::: {.notes}
Three quick ideas‚Äîno jargon, just the practical version.

FIRST: Distributed agency. In real Security Operations Centers, expertise isn't in one place. The AI triages thousands of alerts. Humans decide what's real. Neither has the full picture alone. That's not future-state‚Äîthat's today.

SECOND: Complementary strengths. AI excels at pattern recognition‚Äîspotting anomalies across millions of log entries. Humans excel at context‚Äîunderstanding why something matters, what the organization cares about, what's appropriate to do about it.

THIRD: Mutual shaping. This one's subtle but important. When analysts work with security tools, the tools shape what they notice. The tool decides what to flag, how to prioritize, what to highlight. Over time, analysts learn to think in the tool's categories. That's not bad‚Äîit's just real. And students should understand it.

The activities are designed so students EXPERIENCE these dynamics, not just hear about them.

[For academically-inclined attendees: This draws from posthuman educational theory‚Äîparticularly Braidotti's work on distributed agency and Adams & Thompson's heuristics for examining technology-human entanglement. Full bibliography in your download under "Resources."]
:::

## What You're About to Experience

::: {.fragment}
**Activity 1:** You'll discover that AI caught something you missed‚Äîand YOU caught something AI missed.
:::

::: {.fragment}
**Activity 2:** You'll hear AI articulate its own limitations‚Äîand your policy-making will shift.
:::

::: {.fragment}
**Activity 3:** You'll make decisions a real Incident Response professional makes‚Äîwith AI as your partner.
:::

::: {.fragment style="margin-top: 1em;"}
*These aren't AI literacy lessons. They're partnership training.*
:::

::: {.notes}
Here's what's about to happen‚ÄîI'm telling you now so you can watch for it.

In Activity 1, you're going to investigate a security incident. Pay attention to what YOU notice versus what the AI analysis caught. There's a designed discovery moment.

In Activity 2, you'll design governance policies for an AI system. Then you'll hear the AI describe its own blind spots. Watch what happens to your thinking.

In Activity 3, AI will recommend actions. You'll decide whether to accept, modify, or reject. That's professional judgment.

None of this is about "AI literacy" in the abstract. It's about developing the partnership skills that define modern cybersecurity work.

Ready? Let's experience it.
:::

# {#activity-1 data-menu-title="Activity 1" background-color="#AB0520" background-image="media/banner_reverse.png" background-size="30%" background-position="right 5% top 5%"}

<br /><br />

[ACTIVITY 1]{.r-fit-text}

::: {.all="revert"}
![](media/icon-detective.apng){fig-align="center" width=150}
:::

## Security Detective Teams {background-color="#0C234B"}

**12 minutes**  
**Grades** 6-8 (adaptable K-12)  
**NICE**: Defensive Cybersecurity

::: {.fragment}
**The design:** Students investigate a security incident WITH an AI partner

**The discovery moment:** When students realize AI spotted something they missed‚ÄîAND they spotted something AI missed‚Äîthe partnership insight lands.
:::

::: {.notes}
Activity 1: Security Detective Teams.

**Here's what's about to happen:** You're going to do a 2-minute version of what your students will experience in 35 minutes. Don't just follow the instructions. Pay attention to what YOU notice. What catches YOUR eye first?

[FRAGMENT]

The design is simple: students investigate a security incident with an AI partner. But we've structured the evidence so AI catches certain patterns AND humans catch different ones.

When you experience both, you'll understand exactly what your students will feel.

First, quick implementation note‚Äîthen we dive in.
:::

## Implementation Options {.smaller}

Designed for your actual constraints: **all activities work WITHOUT 1:1 devices**

:::: {.columns}
::: {.column width="50%"}
**Pre-Generated Cards** ‚≠ê *Easiest start*

Print AI response cards: same discovery, zero tech needed

**Teacher-Led Reading**

You read AI analysis aloud; control pacing and emphasis
:::

::: {.column width="50%"}
**Rotation Stations**

One device, groups rotate (5-min turns)

**Live AI Demo**

Project one conversation, whole class analyzes together
:::

::::

::: {.fragment}
*District blocks AI? No devices? The print-based options often work BETTER‚Äîstudents focus on thinking, not clicking.*
:::

::: {.notes}
Four options‚Äîpick what fits YOUR classroom.

Pre-generated cards are the easiest start. Print them, hand them out, done. Same discovery, zero tech dependency.

Teacher-led reading means YOU read the AI analysis aloud. You control pacing, you can emphasize key points, students focus on thinking rather than clicking.

Rotation stations if you have limited devices. Live demo if you want to project one AI conversation for the whole class.

All four work. Technical guides in your download detail each one.

Now let's try it. Your tables are going to investigate a real scenario...
:::

## Scenario: Friday at Lincoln Elementary

:::: {.columns}
::: {.column width="50%"}
::: {.glass-card}
**Your role**: School cybersecurity team

Monday morning email from IT:

> ["Unusual activity on our network Friday night. User account compromised. Need to understand what happened."]{style="font-size: 0.8em;"}
:::
:::

::: {.column width="50%"}
::: {.fragment}
**You have**:

- AI security analysis (technical patterns)
- Access logs (raw data)
- School context (institutional knowledge)

**Your job**: Develop a theory of what happened
:::
:::
::::

::: {.notes}
Quick setup‚Äî30 seconds.

"You're investigators with both AI analysis AND human insight. You've got access logs, AI pattern detection, and one crucial piece of context. Let's see what YOU notice."

Next slide has the evidence. Get ready to investigate.
:::

## The Evidence + AI Analysis {.smaller}

{{< countdown minutes=2 top=0 right=0 left="" >}}

::::: {.columns}

:::: {.column width="50%"}

::: {.glass-card}

**Access Logs (Raw Data)**

- **User**: `jmiller` (school secretary)
- **Compromised**: Friday, 11:47 PM
- **Password**: `Lincoln2024!`
- **Failed logins**: 47 attempts (Friday 10:15-11:45 PM)
- **First unauthorized access**: Personnel records

:::

*School context: Lincoln Elementary announced budget cuts last week affecting support staff positions*

::::

:::: {.column width="50%"}

::: {.glass-card style="border-left: 4px solid #2196F3;"}

**ü§ñ AI Security Analysis**  
*(This is what students see)*

::: {style="font-size: 0.8em;"}
`Pattern detected`  
Password = mascot + year (weak)  
`Threat vector`  
Brute force attack  
`Recommendation`  
Force password reset, enable MFA
:::

:::
**At Your Table (2 min)**

::: {style="font-size: 0.8em;"}
1. Read the AI analysis. What did it catch?
2. Read the school context. What does THAT tell you?
3. What's your theory? Why this person? Why now?
4. Be ready: What did YOU notice that AI didn't?
:::

:::

::::

:::::

::: {.notes}
TABLE ACTIVITY TIME!

Quick framing before you start: "Look at the blue box‚Äîthat's EXACTLY what an AI security tool would output. It caught the password pattern, identified the attack type, gave a recommendation. Good technical analysis. Now look at everything ELSE on this slide..."

[Click countdown]

"Go! Two minutes. Read everything. What do YOU notice?"

Walk around. Listen for

- Who focuses on the AI analysis first?
- Who notices the budget cuts context?
- Does anyone connect secretary + budget cuts + personnel records?

Don't give hints. Let them discover.

After timer: "Before I show you anything‚Äîlet me ask..."
:::

## The Designed Discovery

:::: {.columns}

::: {.column width="50%"}
**AI catches:**

- Password = school mascot + year
- Brute force attempt pattern
- Account compromise indicators
:::

::: {.column width="50%"}
**Humans catch:**

- Budget cuts ‚Üí possible insider motive
- Secretary = access to sensitive files
- *Why this person, why now?*
:::

::::

::: {.fragment}
**The insight:** Neither alone gets the full picture. Students experience this‚Äîthey don't just hear it.
:::

::: {.notes}
Before I show you this‚Äî

"Raise your hand if you noticed the budget cuts connection."

[Hands go up]

"Now raise your hand if AI's password analysis was the first thing you focused on."

[Different hands]

"Look around. Neither group was wrong. You saw DIFFERENT things."

[Reveal slide content]

AI caught: password pattern, brute force signature, technical indicators.

Humans caught: institutional context‚Äîbudget cuts mean someone might be angry, secretary means access to sensitive files, timing matters.

The insight isn't that humans are "better." It's that you see different things. THAT'S what your students will discover.

:::

## Built-In Verification Protocol {.smaller}

**Scaffolded into the activity:**

:::: {.columns}
::: {.column width="50%"}
::: {.glass-card}
1. How would I verify this finding?
2. What other sources should I check?
3. What's the cost if AI is wrong here?
:::
:::

::: {.column width="50%"}
::: {.fragment}
**Why we built this in:**

Students naturally over-trust or under-trust AI. The verification step calibrates appropriate skepticism‚Äîwithout dismissiveness.
:::
:::
::::

::: {.notes}
We built a verification protocol directly into the activity flow.

Here's why: At the college level, we consistently see students swing between two extremes‚Äîeither treating AI as infallible or dismissing it entirely. This protocol addresses that pattern.

The verification checkpoint calibrates appropriate skepticism. Students learn to trust AI outputs AND verify them. That's the professional standard you're preparing them for.

The questions are scaffolded: What would verification look like? What sources? And crucially‚Äîwhat's the cost of being wrong? That last question grounds the abstract in consequences.
:::

## In Your Classroom {.smaller}

:::: {.columns}
::: {.column width="55%"}
**Activity flow (35 min):**

1. **Evidence** (5 min) ‚Äî Present scenario
2. **AI partner** (10 min) ‚Äî Pattern analysis
3. **Human context** (10 min) ‚Äî What AI misses
4. **Synthesis** (10 min) ‚Äî Combine insights
:::

::: {.column width="45%"}
::: {.fragment}
**The download includes:**

- Full lesson plan
- Evidence packets (print-ready)
- AI prompts for students
- **All grade bands: K-2, 3-5, 6-8, 9-12**
:::
:::
::::

::: {.notes}
What you just experienced in 2 minutes? Your students will explore over 35 minutes with full scaffolding.

Present the evidence‚Äî5 minutes. Students partner with AI for pattern analysis‚Äî10 minutes. Then the crucial step: What does AI miss? 10 minutes. Finally, synthesis.

The download includes everything‚Äîbut start with the Quick Start guide, not the full curriculum. It tells you exactly what to do first.

AND‚Äîgrade-band versions for ALL ages. K-2, 3-5, 6-8, and 9-12. Same core discovery, adapted to developmental level.

That "aha" you felt? Your students will feel it too.
:::

# {#activity-2 data-menu-title="Activity 2" background-color="#0C234B" background-image="media/banner_reverse.png" background-size="30%" background-position="right 5% top 5%"}

<br /><br />

[ACTIVITY 2]{.r-fit-text}

::: {.all="revert"}
![](media/icon-scale.apng){fig-align="center" width=150}
:::

## Ethics in Automated Security {background-color="#0C234B"}

**12 minutes**  
**Grades** 6-8 (available K-12)  
**NICE**: Cybersecurity Policy and Planning

::: {.fragment}
**The design:** Students design governance policies for AI security systems

**The discovery moment:** When they hear AI articulate its own limitations, policy design becomes collaborative‚Äînot just restrictive.
:::

::: {.notes}
Activity 2: Ethics in Automated Security.

**The progression:** In Activity 1, you partnered with AI to INVESTIGATE.

[NEXT]

Now you're designing rules FOR AI‚Äîmoving from "working together" to "governing together." That's a higher-order skill.

**Same deal:** 4-minute version here, 40 minutes with full scaffolding in your classroom.

Watch what happens to your thinking when AI tells you what it CAN'T do.
:::

## The Setup

:::: {.columns}
::: {.column width="65%"}
::: {.glass-card}
**Scenario:** Your school is getting "SchoolGuard"

**It can:**

- See what websites students visit
- Block "dangerous" sites
- Alert teachers about "unusual" activity
- Learn from student behavior patterns
:::
:::

::: {.column width="35%"}
::: {.fragment}
### Your job:

Decide what SchoolGuard should do **automatically** vs. **ask humans first**
:::
:::
::::

::: {.notes}
Here's the scenario: Your school is implementing an AI security system called SchoolGuard.

It can monitor website visits, block dangerous sites, alert teachers about unusual activity, and learn from patterns.

‚Üí PAUSE

Your job‚Äîand the students' job‚Äîis to decide: What should SchoolGuard do automatically? What should require human approval first?

Let's design some policies together.
:::

## Your Table's Policy Challenge (4 min)

**Your table designs ONE policy:**

::: {.glass-card}
> "SchoolGuard should _____________ automatically, but must ask a human before _____________."
:::

**Think about:**

- What's the RISK if SchoolGuard acts alone?
- What's the COST if humans must approve everything?
- Where's the line?

{{< countdown minutes=4 >}}

::: {.notes}
TABLE ACTIVITY TIME!

[Click countdown] "Go! Four minutes. Design ONE policy. Think about the trade-offs."

Walk around and listen. You'll hear very different approaches‚Äîsafety vs. privacy vs. efficiency. Don't intervene. Let them wrestle with it.

When the timer finishes: "Hold onto your policies. Before we share‚ÄîI want you to hear from the AI itself..."
:::

## What Does the AI Say? {.smaller}

:::: {.columns}
::: {.column width="50%"}
::: {.glass-card}
**What I CAN do:**

"I spot patterns humans miss. I've identified students at risk of self-harm weeks before any visible signs."
:::
:::

::: {.column width="50%"}
::: {.fragment .glass-card}
**What I CAN'T do:**

"I flagged a student researching gun violence for a **history paper**. I see patterns, not intentions."
:::
:::
::::

::: {.notes}
[Read the AI's voice dramatically]

"What I CAN do: I spot patterns humans miss. I've identified students at risk of self-harm weeks before any visible signs."

[Pause. Let that land.]

[Reveal the second box]

"What I CAN'T do: I flagged a student researching gun violence for a history paper. I see patterns, not intentions."

Now ask: "How many of you wrote policies mostly about RESTRICTING what AI can do?" [Hands.] "Now that you've heard AI describe its own blind spots‚Äîwould you write it differently?"

That shift‚Äîfrom "how do we control AI?" to "how do we design smart handoffs?"‚ÄîTHAT'S the insight.
:::

## Share Your Policies (2 min)

**2-3 tables: What did you decide?**

::: {.fragment}
The design insight: did hearing what AI can and can't do change your thinking? That shift, from *controlling AI* to *partnering with AI*, is exactly what we want students to discover.
:::

::: {.notes}
"2-3 tables‚Äîwhat did you decide?"

[Listen for variety: automation vs. approval vs. specific scenarios]

After sharing: "Did hearing AI's perspective change how you'd write it? Look around‚Äîsome of you are nodding."

"That shift you just felt? From 'control AI' to 'design smart handoffs'? That's what your students will feel."
:::

## In Your Classroom {.smaller}

:::: {.columns}
::: {.column width="55%"}
**Activity flow (40 min):**

1. **Scenario** (5 min) ‚Äî Intro SchoolGuard
2. **Policy design** (15 min) ‚Äî 3 decisions
3. **AI perspective** (5 min) ‚Äî Capabilities & limits
4. **Debate** (10 min) ‚Äî Defend choices
5. **Reflection** (5 min) ‚Äî What's hard?
:::

::: {.column width="45%"}
::: {.fragment}
**Grade-band versions:**

- **K-2:** "Robot Helper Rules"
- **3-5:** "Computer Rules Committee"
- **9-12:** "AI Governance Workshop"

*All include scenario cards + AI voice scripts*
:::
:::
::::

::: {.notes}
What you just experienced in 4 minutes? Your students get 40 minutes with full scaffolding.

Scenario intro, policy design for 3 questions (not just one), AI perspective reveal, class debate, reflection.

Grade-band versions:

K-2: "Robot Helper Rules"‚Äîclassroom robot Sparky. What can Sparky do alone vs. ask first?

3-5: "Computer Rules Committee"‚Äîschool tech policies.

9-12: "AI Governance Workshop"‚Äîactual legal frameworks like FERPA, stakeholder role-play.

Same discovery, adapted to developmental level.
:::

# {#third-activity data-menu-title="The Third Activity" background-image="media/banner.png" background-size="30%" background-position="right 5% top 5%"}

<br /><br />

[ACTIVITY 3]{.r-fit-text}

::: {.all="revert"}
![](media/icon-shield.apng){fig-align="center" width=150}
:::

## AI-Assisted Incident Response {background-color="#0C234B"}

**3 minutes**  
**Grades** 6-8 (available K-12)  
**NICE**: Incident Response

::: {.fragment}
**The design:** AI recommends actions, humans decide

**The discovery moment:** Students realize they're making real career decisions‚ÄîIncident Response is a real career.
:::

::: {.notes}
Activity 3: AI-Assisted Incident Response. Fastest one‚Äî90 seconds.

**The progression:** Activity 1 was investigating together. Activity 2 was governing together. Now: DECIDING together under pressure. AI recommends, you choose. That's the full partnership arc‚Äîanalysis, policy, action.

Ready? Here's your incident.
:::

## Incident Response Challenge (90 sec) {.smaller}

::: {.glass-card style="border-left: 4px solid #AB0520;"}
**üö® ALERT:** Ransomware detected on 3 teacher workstations. Spreading to shared drive.
:::

**AI Security System recommends:**

| # | Recommendation | Your Call |
|---|----------------|-----------|
| 1 | Isolate infected machines immediately | *(auto-approved)* |
| 2 | Lock ALL user accounts until investigation complete | ? |
| 3 | Notify parents about potential data exposure | ? |

**At your table:** For #2 and #3‚Äî**ACCEPT**, **MODIFY**, or **REJECT**?

Think: *What happens if we do this? What happens if we don't?*

{{< countdown seconds=90 >}}

::: {.notes}
[Click countdown] "Go! 90 seconds. For recommendations 2 and 3‚Äîaccept as-is, modify, or reject?"

Frame it: "Think 'what if'‚ÄîWhat if you lock all accounts? Teachers can't access lesson plans. What if you DON'T? Ransomware spreads. What if you notify parents now? Panic. What if you wait? Liability."

Walk around quickly. Listen for disagreement‚Äîthat's good. Some will say "lock everyone out, safety first." Others will say "that's overreach."

After timer: "Quick show of hands‚Äîwho accepted #2? Who modified? Who rejected?"
:::

## The Career Connection

::: {.fragment}
**You just made decisions an Incident Response professional makes daily.**

That's the Incident Response work role in the NICE Framework.
:::

::: {.fragment}
AI gave options. You used judgment. **That's the partnership.**

*Full 35-minute version in your download‚Äîwith role cards for Analyst, Manager, Communications Lead.*
:::

::: {.notes}
"Raise your hand if you accepted recommendation #2‚Äîlock all accounts." [Hands]

"Raise your hand if you rejected or modified it." [Hands]

"That disagreement? That's EXACTLY what happens in real incident response. There's no single right answer. What matters is the reasoning."

You just did what Incident Response professionals do. That's a real career in the NICE Framework. Your students can see themselves in that role.

What you experienced in 90 seconds, your students get 35 minutes with full scaffolding, role cards, and multiple incidents.
:::

# {#why-it-works data-menu-title="Why This Works" background-color="#0C234B" background-image="media/banner_reverse.png" background-size="30%" background-position="right 5% top 5%"}

<br /><br />

[WHY THIS WORKS]{.r-fit-text}

::: {.all="revert"}
![](media/icon-brain.apng){fig-align="center" width=150}
:::

## What You Just Discovered

::: {.fragment}
**Activity 1:** AI sees patterns. Humans see context. *Together: the full picture.*
:::

::: {.fragment}
**Activity 2:** AI has limits it can name. Humans design smart handoffs. *Together: better governance.*
:::

::: {.fragment}
**Activity 3:** AI recommends. Humans decide. *Together: professional judgment.*
:::

::: {.notes}
Let's name what just happened.

In Activity 1, you discovered that AI catches technical patterns‚Äîbut YOU caught the institutional context. Neither alone got the full picture.

In Activity 2, you heard AI articulate its own blind spots‚Äîand your policy-making shifted from "control AI" to "design smart handoffs."

In Activity 3, AI gave options. You made judgment calls. That's professional practice.

Three activities. Three discoveries. Your students will feel exactly what you felt.
:::

# {#implementation data-menu-title="What You're Getting" background-image="media/banner.png" background-size="30%" background-position="right 5% top 5%"}

<br /><br />

[WHAT YOU'RE GETTING]{.r-fit-text}

::: {.all="revert"}
![](media/icon-book.apng){fig-align="center" width=150}
:::

## Your Complete Download Package {.smaller}

:::: {.columns}

::: {.column width="50%"}
**üìö 12 Complete Lesson Plans**

- 3 activities √ó 4 grade bands (K-2 through 9-12)
- Full facilitation guides
- Differentiation strategies

**üìä Assessment & Career**

- Human-AI Collaboration rubrics
- NICE Framework Alignment Matrix
- Career connection handouts
- Work role mappings
:::

::: {.column width="50%"}
**üîß Implementation Support**

- **Low-Resource Guide** ‚≠ê (often works BETTER)
- AI Platform Setup guides
- CTE program alignment
- Outreach/STEAM integration

**üìù Ready-to-Print Materials**

- Evidence packets & worksheets
- Role cards & scenario cards
- AI response cards (low-resource)
- Annotated bibliography
:::

::::

::: {.notes}
Let me quickly run through what you're getting‚Äîit's substantial.

Twelve complete lesson plans: three activities, each with four grade-band versions from K-2 through high school.

Assessment rubrics focused on what actually matters‚Äîhow well students collaborate with AI, not just individual knowledge. Plus career connection handouts that link every activity to NICE Framework work roles.

Implementation support for YOUR context. And I want to highlight the Low-Resource Guide‚Äîthis isn't a compromise. Teachers tell us the print-based versions often work BETTER because students focus on the thinking, not the clicking. Start there.

CTE pathway alignment, outreach program guidance, and print-ready materials you can use Monday.
:::

## NICE Framework Alignment {.smaller}

**Mapped to Work Roles‚Äîdownloadable crosswalks included:**

| Activity | Primary Work Roles (v2.0.0) |
|----------|-------------------|
| Security Detective Teams | Defensive Cybersecurity, Vulnerability Analysis (PD) |
| Ethics in Automated Security | Cybersecurity Policy and Planning, Privacy Compliance (OG) |
| AI-Assisted Incident Response | Incident Response, Defensive Cybersecurity, Threat Analysis (PD) |

::: {.fragment}
**Implementation note:** Career connection handouts link activity tasks to specific TKS statements. Full competency mapping available in download, ready for CTE pathway and curriculum approval documentation.
:::

::: {.notes}
You'll find NICE Framework crosswalks in the download‚Äîeach activity mapped to Work Roles with specific TKS alignments.

For those of you building CTE pathways or documenting curriculum alignment, these are ready to use. Work Role names are current with Framework 2.0.0.

The career connection handouts translate activity tasks into language students‚Äîand administrators‚Äîcan connect to workforce outcomes.
:::

## Implementation Considerations

::: {.r-fit-text}
**As you plan adaptation...**
:::

- What's your current AI access reality? (Low-resource options are robust)
- Which discovery moments matter most for your students?
- How do these connect to existing curriculum?
- What adaptations are you already considering?

::: {.notes}
A few implementation considerations as you plan:

AI access: The low-resource options aren't compromises‚Äîthey're often pedagogically stronger because they force focus on the thinking rather than the technology.

Discovery moments: Different contexts may emphasize different insights. The materials are modular enough to prioritize what matters for your students.

Curriculum connections: Where do these fit in what you're already doing? They're designed as standalone activities but also as entry points.

What adaptations are you already thinking about? Let's discuss.
:::

# {#questions data-menu-title="Questions" background-image="media/banner.png" background-size="30%" background-position="right 5% top 5%"}

<br /><br />

[QUESTIONS?]{.r-fit-text}

::: {.all="revert"}
![](media/icon-question.apng){fig-align="center" width=150}
:::

## {#closing background-color="#0C234B"}

::: {style="text-align: center; color: #FFFFFF;"}
[**Get the Materials!**]{style="font-size: 2em;"}

![](media/qr-nicek12.png){width=200px}

[ryanstraight.github.io/nicek12&#x2011;2025&#x2011;materials](https://ryanstraight.github.io/nicek12-2025-materials/){style="color: #81D3EB;"}

*12 lesson plans ‚Ä¢ Career connections ‚Ä¢ Any resource level*

[**Presented by:** [Ryan Straight](mailto:ryanstraight@arizona.edu), [Rob Honomichl](mailto:rjhonomichl@arizona.edu), & [Paul Wagner](mailto:paulewagner@arizona.edu)]{style="font-size: 0.7em;"}  
[Cyber Operations]{style="font-size: 0.7em;"}  
[College of Information Science]{style="font-size: 0.7em;"}  
[University of Arizona]{style="font-size: 0.7em;"}
:::

::: {.notes}
Thank you!

One more time‚Äîif you haven't downloaded yet, do it now. QR code is right there.

We'd love to hear how you implement these. Email me at ryanstraight@arizona.edu‚ÄîI genuinely want to know what works and what doesn't in different classroom contexts.

Let's take questions!
:::
